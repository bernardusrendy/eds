{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the dataset ...\n",
      "Training ...\n",
      "mse on training data =       0.2744735958\n",
      "r2 on training data  =       0.8217991925\n",
      "mse on testing data =       0.2887086351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection as modsel\n",
    "from sklearn import linear_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "RANDSEED = 40\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(RANDSEED)\n",
    "\n",
    "# Load dataset \"Iris\" pada variable df\n",
    "def get_iris_df():\n",
    "    ds = sklearn.datasets.load_iris()\n",
    "    df = pd.DataFrame(ds['data'],\n",
    "    columns = ds['feature_names'])\n",
    "    code_species_map = dict(zip(\n",
    "    range(3), ds['target_names']))\n",
    "    df['species'] = [code_species_map[c]\n",
    "    for c in ds['target']]\n",
    "    return df\n",
    "df = get_iris_df()\n",
    "\n",
    "X1=df[['petal length (cm)','petal width (cm)']].values\n",
    "X2=df[['petal length (cm)','sepal width (cm)']].values\n",
    "\n",
    "# Prepare for lasso regression\n",
    "lassoreg = linear_model.Lasso()\n",
    "\n",
    "# split dataset, 10 percent for test\n",
    "print('Splitting the dataset ...')\n",
    "X_train, X_test, y_train, y_test = modsel.train_test_split(\n",
    "    X1, X2, test_size=0.5, random_state=RANDSEED\n",
    ")\n",
    "\n",
    "# do the training (fitting)\n",
    "print('Training ...')\n",
    "lassoreg.fit(X_train, y_train)\n",
    "\n",
    "# mean-squred error\n",
    "mse = metrics.mean_squared_error(y_train, lassoreg.predict(X_train))\n",
    "print('mse on training data = %18.10f' % mse)\n",
    "\n",
    "# r2 scoring from lassoreg\n",
    "r2 = lassoreg.score(X_train, y_train)\n",
    "print('r2 on training data  = %18.10f' % r2)\n",
    "\n",
    "# predicted on test data\n",
    "y_pred = lassoreg.predict(X_test)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "print('mse on testing data = %18.10f' % mse)\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(y_test, linewidth=3, label='ground truth')\n",
    "plt.plot(y_pred, linewidth=3, label='predicted')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('test data points')\n",
    "plt.ylabel('target value')\n",
    "plt.savefig('04_truth_vs_predicted.png', dpi=300)\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(y_test, y_pred, 'o')\n",
    "plt.plot([-10,60], [-10,60], '--')\n",
    "plt.axis([-10, 60, -10, 60])\n",
    "plt.xlabel('ground truth')\n",
    "plt.ylabel('predicted')\n",
    "\n",
    "scorestr = r'$R^2$ = %.3f' % lassoreg.score(X_test, y_test)\n",
    "errstr = 'MSE = %.3f' % metrics.mean_squared_error(y_test, y_pred)\n",
    "plt.text(-5,50, scorestr, fontsize=12)\n",
    "plt.text(-5,45, errstr, fontsize=12)\n",
    "\n",
    "plt.savefig('04_truth_vs_predicted_v2.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
